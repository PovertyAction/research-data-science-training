---
title: "Complete R Data Science Workflow in Positron"
abstract: |
  This tutorial demonstrates a complete R data science project workflow in Positron. You will learn to organize R projects, manipulate data with dplyr and tidyr, create visualizations with ggplot2, perform statistical analysis, and create reproducible reports using Quarto.
date: last-modified

format:
  html: default

authors:
  - "[Niall Keleher](https://poverty-action.org/people/niall-keleher)"

# # Contributors
# contributors:
#   - "[Contributor Name](https://poverty-action.org/people/contributor_name)"

keywords: ["Positron", "R", "Tidyverse", "ggplot2", "Data Science", "Workflow", "Tutorial", "Diátaxis Framework"]
license: "CC BY-SA 4.0"
---

## Learning Objectives

By the end of this tutorial, you will be able to:

- Set up a complete R data science project in Positron
- Use the tidyverse ecosystem for data manipulation and visualization
- Perform statistical analysis and modeling in R
- Create professional visualizations with ggplot2
- Generate reproducible reports with Quarto
- Follow R data science best practices in Positron

## Prerequisites

Before starting, ensure you have:
- ✅ Positron installed and configured
- ✅ R interpreter set up with tidyverse packages
- ✅ Familiarity with Positron's interface and data exploration tools

## Project Overview

We'll analyze a dataset about passenger characteristics from the Titanic disaster. Our goals:

1. **Research Question**: What factors influenced passenger survival on the Titanic?
2. **Dataset**: Titanic passenger data
3. **Deliverable**: Statistical analysis with visualizations and report

## Part 1: Setting Up the R Project

### Step 1: Create Project Structure

1. **Create project folder**:
   ```bash
   mkdir titanic_analysis_r
   ```

2. **Open in Positron**: `File > Open Folder` → select `titanic_analysis_r`

3. **Create R project structure**:
   ```
   titanic_analysis_r/
   ├── data/           # Raw and processed data
   ├── scripts/        # R scripts
   ├── plots/          # Generated plots
   ├── reports/        # Analysis reports
   └── README.md       # Project documentation
   ```

4. **Create directories**:
   ```bash
   mkdir data scripts plots reports
   ```

### Step 2: Install and Load Required Packages

Create `scripts/setup.R`:

```r
# Install required packages (run once)
required_packages <- c(
  "tidyverse",    # Data manipulation and visualization
  "plotly",       # Interactive plots
  "corrplot",     # Correlation plots
  "VIM",          # Missing data visualization
  "caret",        # Machine learning
  "rmarkdown",    # Report generation
  "DT"            # Interactive tables
)

# Install missing packages
new_packages <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) {
  install.packages(new_packages)
}

# Load packages
library(tidyverse)
library(plotly)
library(corrplot)
library(VIM)
library(caret)
library(DT)

cat("All packages loaded successfully!\n")
```

**Run the setup**: Select all code and press `F9`

::: {.callout-note}
The tidyverse is a collection of R packages designed for data science that work harmoniously together.
:::

## Part 2: Data Import and Exploration

### Step 1: Load the Titanic Dataset

Create `scripts/titanic_analysis.R`:

```r
# Load required libraries
library(tidyverse)
library(plotly)

# Load Titanic dataset (built-in to R)
data("Titanic")

# Convert to data frame for easier manipulation
titanic_df <- as.data.frame(Titanic)

# Expand the frequency table to individual observations
titanic_expanded <- titanic_df[rep(row.names(titanic_df), titanic_df$Freq), -5]

# Alternative: Load from online source for more detailed data
url <- "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
titanic_detailed <- read_csv(url)

cat("Datasets loaded successfully!\n")
cat("Simple dataset:", nrow(titanic_expanded), "rows\n")
cat("Detailed dataset:", nrow(titanic_detailed), "rows\n")

# Use the detailed dataset for our analysis
titanic <- titanic_detailed
```

### Step 2: Initial Data Exploration

```r
# Basic dataset information
cat("=== Dataset Overview ===\n")
print(dim(titanic))
print(head(titanic))

cat("\n=== Column Names ===\n")
print(names(titanic))

cat("\n=== Data Structure ===\n")
print(str(titanic))

cat("\n=== Summary Statistics ===\n")
print(summary(titanic))

cat("\n=== Missing Values ===\n")
missing_summary <- titanic %>%
  summarise_all(~sum(is.na(.))) %>%
  gather(key = "Variable", value = "Missing_Count") %>%
  mutate(Missing_Percent = round(Missing_Count / nrow(titanic) * 100, 2)) %>%
  arrange(desc(Missing_Count))

print(missing_summary)
```

**Run and explore**: Check the Variables panel and Data Viewer for the `titanic` dataset.

## Part 3: Data Cleaning and Preparation

### Step 1: Clean and Prepare Data

```r
# Data cleaning and preparation
cat("=== Data Cleaning ===\n")

# Select relevant columns and clean data
titanic_clean <- titanic %>%
  select(PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Fare, Embarked) %>%

  # Convert categorical variables to factors
  mutate(
    Survived = factor(Survived, levels = c(0, 1), labels = c("No", "Yes")),
    Pclass = factor(Pclass, levels = c(1, 2, 3), labels = c("First", "Second", "Third")),
    Sex = factor(Sex),
    Embarked = factor(Embarked)
  ) %>%

  # Handle missing values
  mutate(
    Age = ifelse(is.na(Age), median(Age, na.rm = TRUE), Age),
    Embarked = ifelse(is.na(Embarked) | Embarked == "", "S", Embarked)
  ) %>%

  # Create new variables
  mutate(
    FamilySize = SibSp + Parch + 1,
    AgeGroup = cut(Age, breaks = c(0, 12, 18, 35, 60, 100),
                   labels = c("Child", "Teen", "Adult", "Middle", "Senior")),
    FareGroup = cut(Fare, breaks = c(-Inf, 10, 30, 100, Inf),
                    labels = c("Low", "Medium", "High", "Very High"))
  ) %>%

  # Remove rows with missing Fare (very few)
  filter(!is.na(Fare))

cat("Cleaned dataset:", nrow(titanic_clean), "rows\n")

# Check our cleaned data
cat("\n=== Cleaned Data Summary ===\n")
print(summary(titanic_clean))
```

### Step 2: Exploratory Data Analysis

```r
# Basic survival statistics
cat("=== Survival Statistics ===\n")
survival_summary <- titanic_clean %>%
  group_by(Survived) %>%
  summarise(Count = n(), .groups = 'drop') %>%
  mutate(Percentage = round(Count / sum(Count) * 100, 1))

print(survival_summary)

# Survival by key factors
cat("\n=== Survival by Passenger Class ===\n")
class_survival <- titanic_clean %>%
  group_by(Pclass, Survived) %>%
  summarise(Count = n(), .groups = 'drop') %>%
  group_by(Pclass) %>%
  mutate(Percentage = round(Count / sum(Count) * 100, 1))

print(class_survival)

cat("\n=== Survival by Gender ===\n")
gender_survival <- titanic_clean %>%
  group_by(Sex, Survived) %>%
  summarise(Count = n(), .groups = 'drop') %>%
  group_by(Sex) %>%
  mutate(Percentage = round(Count / sum(Count) * 100, 1))

print(gender_survival)
```

**Check Variables Panel**: You should see all the new data frames and summaries.

## Part 4: Data Visualization with ggplot2

### Step 1: Basic Survival Visualizations

```r
# Load ggplot2 for plotting
library(ggplot2)

cat("=== Creating Visualizations ===\n")

# 1. Overall survival distribution
p1 <- ggplot(titanic_clean, aes(x = Survived, fill = Survived)) +
  geom_bar(alpha = 0.7) +
  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +
  labs(title = "Titanic Survival Distribution",
       x = "Survived", y = "Count") +
  scale_fill_manual(values = c("No" = "red", "Yes" = "green")) +
  theme_minimal()

print(p1)

# 2. Survival by passenger class
p2 <- ggplot(titanic_clean, aes(x = Pclass, fill = Survived)) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Survival by Passenger Class",
       x = "Passenger Class", y = "Count") +
  scale_fill_manual(values = c("No" = "red", "Yes" = "green")) +
  theme_minimal()

print(p2)

# 3. Survival by gender
p3 <- ggplot(titanic_clean, aes(x = Sex, fill = Survived)) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Survival by Gender",
       x = "Gender", y = "Count") +
  scale_fill_manual(values = c("No" = "red", "Yes" = "green")) +
  theme_minimal()

print(p3)

# 4. Age distribution by survival
p4 <- ggplot(titanic_clean, aes(x = Age, fill = Survived)) +
  geom_histogram(alpha = 0.7, bins = 30, position = "identity") +
  labs(title = "Age Distribution by Survival",
       x = "Age", y = "Count") +
  scale_fill_manual(values = c("No" = "red", "Yes" = "green")) +
  theme_minimal() +
  facet_wrap(~Survived)

print(p4)
```

### Step 2: Advanced Visualizations

```r
# 5. Survival by multiple factors
p5 <- ggplot(titanic_clean, aes(x = Pclass, fill = Survived)) +
  geom_bar(position = "fill", alpha = 0.7) +
  labs(title = "Survival Proportion by Class and Gender",
       x = "Passenger Class", y = "Proportion") +
  scale_fill_manual(values = c("No" = "red", "Yes" = "green")) +
  theme_minimal() +
  facet_wrap(~Sex)

print(p5)

# 6. Fare distribution by survival
p6 <- ggplot(titanic_clean, aes(x = Survived, y = Fare, fill = Survived)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Fare Distribution by Survival",
       x = "Survived", y = "Fare") +
  scale_fill_manual(values = c("No" = "red", "Yes" = "green")) +
  theme_minimal()

print(p6)

# 7. Family size vs survival
p7 <- ggplot(titanic_clean, aes(x = factor(FamilySize), fill = Survived)) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(title = "Survival by Family Size",
       x = "Family Size", y = "Count") +
  scale_fill_manual(values = c("No" = "red", "Yes" = "green")) +
  theme_minimal()

print(p7)

# 8. Correlation matrix for numeric variables
numeric_vars <- titanic_clean %>%
  select(Age, SibSp, Parch, Fare, FamilySize) %>%
  mutate(Survived_num = as.numeric(titanic_clean$Survived) - 1)

correlation_matrix <- cor(numeric_vars, use = "complete.obs")

# Create correlation plot
library(corrplot)
corrplot(correlation_matrix, method = "color", type = "upper",
         order = "hclust", tl.cex = 0.8, tl.col = "black")
title("Correlation Matrix of Numeric Variables")
```

**Check Plots Panel**: Navigate through all the visualizations you've created.

## Part 5: Statistical Analysis

### Step 1: Survival Analysis by Factors

```r
cat("=== Statistical Analysis ===\n")

# Chi-square tests for categorical variables
cat("\n--- Chi-square Tests ---\n")

# Class and Survival
class_test <- chisq.test(titanic_clean$Pclass, titanic_clean$Survived)
cat("Passenger Class vs Survival:\n")
print(class_test)

# Gender and Survival
gender_test <- chisq.test(titanic_clean$Sex, titanic_clean$Survived)
cat("\nGender vs Survival:\n")
print(gender_test)

# Age group and Survival
age_test <- chisq.test(titanic_clean$AgeGroup, titanic_clean$Survived)
cat("\nAge Group vs Survival:\n")
print(age_test)

# T-tests for continuous variables
cat("\n--- T-tests ---\n")

# Age difference between survivors and non-survivors
age_test <- t.test(Age ~ Survived, data = titanic_clean)
cat("Age difference between survivors and non-survivors:\n")
print(age_test)

# Fare difference between survivors and non-survivors
fare_test <- t.test(Fare ~ Survived, data = titanic_clean)
cat("\nFare difference between survivors and non-survivors:\n")
print(fare_test)
```

### Step 2: Logistic Regression Model

```r
# Logistic regression model
cat("\n=== Logistic Regression Model ===\n")

# Prepare data for modeling
model_data <- titanic_clean %>%
  select(Survived, Pclass, Sex, Age, FamilySize, Fare) %>%
  mutate(
    Survived_binary = as.numeric(Survived) - 1,
    Pclass_num = as.numeric(Pclass),
    Sex_num = as.numeric(Sex) - 1  # 0 = female, 1 = male
  )

# Fit logistic regression model
logit_model <- glm(Survived_binary ~ Pclass_num + Sex_num + Age + FamilySize + Fare,
                   data = model_data, family = binomial)

# Model summary
cat("Model Summary:\n")
print(summary(logit_model))

# Calculate odds ratios
odds_ratios <- exp(coef(logit_model))
cat("\nOdds Ratios:\n")
print(odds_ratios)

# Model predictions
predictions <- predict(logit_model, type = "response")
predicted_class <- ifelse(predictions > 0.5, 1, 0)

# Model accuracy
accuracy <- mean(predicted_class == model_data$Survived_binary, na.rm = TRUE)
cat(sprintf("\nModel Accuracy: %.3f\n", accuracy))

# Confusion matrix
confusion_matrix <- table(Predicted = predicted_class, Actual = model_data$Survived_binary)
cat("\nConfusion Matrix:\n")
print(confusion_matrix)
```

### Step 3: Model Visualization

```r
# Model results visualization
library(ggplot2)

# Predicted probabilities vs actual survival
model_results <- data.frame(
  Actual = model_data$Survived_binary,
  Predicted_Prob = predictions,
  Predicted_Class = predicted_class
)

# ROC-style visualization
p8 <- ggplot(model_results, aes(x = Predicted_Prob, fill = factor(Actual))) +
  geom_histogram(alpha = 0.7, bins = 20, position = "identity") +
  labs(title = "Distribution of Predicted Probabilities",
       x = "Predicted Probability of Survival",
       y = "Count",
       fill = "Actual Survival") +
  scale_fill_manual(values = c("0" = "red", "1" = "green"),
                    labels = c("No", "Yes")) +
  theme_minimal()

print(p8)

# Feature importance plot (coefficient magnitudes)
coef_df <- data.frame(
  Variable = names(coef(logit_model))[-1],  # Exclude intercept
  Coefficient = coef(logit_model)[-1],
  Odds_Ratio = odds_ratios[-1]
)

p9 <- ggplot(coef_df, aes(x = reorder(Variable, abs(Coefficient)), y = Coefficient)) +
  geom_col(fill = "steelblue", alpha = 0.7) +
  coord_flip() +
  labs(title = "Logistic Regression Coefficients",
       x = "Variable", y = "Coefficient") +
  theme_minimal()

print(p9)
```

## Part 6: Advanced Analysis and Interactive Plots

### Step 1: Interactive Visualizations with plotly

```r
# Interactive visualizations with plotly
library(plotly)

cat("=== Creating Interactive Plots ===\n")

# Interactive survival by age and fare
p_interactive <- ggplot(titanic_clean, aes(x = Age, y = Fare, color = Survived,
                                          text = paste("Name:", Name,
                                                      "<br>Class:", Pclass,
                                                      "<br>Sex:", Sex))) +
  geom_point(alpha = 0.7) +
  labs(title = "Age vs Fare by Survival (Interactive)",
       x = "Age", y = "Fare") +
  scale_color_manual(values = c("No" = "red", "Yes" = "green")) +
  theme_minimal()

# Convert to interactive plot
interactive_plot <- ggplotly(p_interactive, tooltip = "text")
print(interactive_plot)

# Interactive survival rates by group
survival_rates <- titanic_clean %>%
  group_by(Pclass, Sex) %>%
  summarise(
    Total = n(),
    Survived_Count = sum(as.numeric(Survived) - 1),
    Survival_Rate = Survived_Count / Total,
    .groups = 'drop'
  )

p_rates <- ggplot(survival_rates, aes(x = Pclass, y = Survival_Rate, fill = Sex,
                                     text = paste("Class:", Pclass,
                                                 "<br>Sex:", Sex,
                                                 "<br>Rate:", round(Survival_Rate, 3)))) +
  geom_col(position = "dodge", alpha = 0.7) +
  labs(title = "Survival Rates by Class and Gender",
       x = "Passenger Class", y = "Survival Rate") +
  theme_minimal()

interactive_rates <- ggplotly(p_rates, tooltip = "text")
print(interactive_rates)
```

## Part 7: Report Generation with Quarto

### Step 1: Create a Quarto Report

Create `reports/titanic_analysis_report.qmd`:

```yaml
---
title: "Titanic Survival Analysis Report"
author: "Your Name"
date: "`r Sys.Date()`"
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    theme: cosmo
---
```

```r
# Setup chunk
#| include: false
library(tidyverse)
library(plotly)
library(DT)
library(knitr)

# Load cleaned data (you would load your processed data here)
# For this example, we'll recreate key objects
```

```markdown
## Executive Summary

This report analyzes passenger survival data from the RMS Titanic disaster of 1912.
Our analysis reveals several key factors that significantly influenced survival rates:

- **Gender**: Women had a much higher survival rate than men
- **Passenger Class**: First-class passengers had better survival odds
- **Age**: Children had higher survival rates than adults
- **Fare**: Higher fare (proxy for wealth) correlated with survival

## Data Overview

The dataset contains information on **`r nrow(titanic_clean)`** passengers with the following characteristics:
```

Continue building the Quarto report with alternating text and code chunks.

### Step 2: Generate Professional Tables

```r
# Create professional tables with DT
cat("=== Creating Interactive Tables ===\n")

# Summary statistics table
summary_table <- titanic_clean %>%
  group_by(Pclass, Sex) %>%
  summarise(
    Count = n(),
    Avg_Age = round(mean(Age, na.rm = TRUE), 1),
    Avg_Fare = round(mean(Fare, na.rm = TRUE), 2),
    Survival_Rate = round(mean(as.numeric(Survived) - 1), 3),
    .groups = 'drop'
  )

# Display interactive table
datatable(summary_table,
          caption = "Summary Statistics by Class and Gender",
          options = list(pageLength = 10))

# Model results table
model_summary_table <- data.frame(
  Variable = names(coef(logit_model)),
  Coefficient = round(coef(logit_model), 4),
  Odds_Ratio = round(exp(coef(logit_model)), 4),
  P_Value = round(summary(logit_model)$coefficients[,4], 4)
)

datatable(model_summary_table,
          caption = "Logistic Regression Results",
          options = list(pageLength = 10)) %>%
  formatRound(columns = c("Coefficient", "Odds_Ratio"), digits = 4)
```

## Part 8: Save Results and Export

### Step 1: Save All Objects and Plots

```r
# Save analysis results
cat("=== Saving Results ===\n")

# Save cleaned data
write_csv(titanic_clean, "data/titanic_clean.csv")

# Save analysis results
write_csv(survival_rates, "data/survival_rates_by_group.csv")
write_csv(summary_table, "data/summary_statistics.csv")

# Save model results
saveRDS(logit_model, "data/logistic_regression_model.rds")

# Save plots programmatically
ggsave("plots/survival_distribution.png", p1, width = 8, height = 6, dpi = 300)
ggsave("plots/survival_by_class.png", p2, width = 8, height = 6, dpi = 300)
ggsave("plots/survival_by_gender.png", p3, width = 8, height = 6, dpi = 300)
ggsave("plots/age_distribution.png", p4, width = 10, height = 6, dpi = 300)
ggsave("plots/class_gender_survival.png", p5, width = 10, height = 6, dpi = 300)

cat("All results saved successfully!\n")

# Create a comprehensive summary
analysis_summary <- list(
  dataset_info = list(
    total_passengers = nrow(titanic_clean),
    survivors = sum(titanic_clean$Survived == "Yes"),
    survival_rate = mean(titanic_clean$Survived == "Yes")
  ),
  key_findings = list(
    gender_effect = "Women had 3x higher survival rate than men",
    class_effect = "First class passengers had highest survival rates",
    age_effect = "Children and younger passengers had better survival odds"
  ),
  model_performance = list(
    accuracy = accuracy,
    significant_predictors = c("Gender", "Class", "Age")
  )
)

# Save summary
saveRDS(analysis_summary, "data/analysis_summary.rds")
```

### Step 2: Generate Final Report

```r
# Create final summary report
final_report <- sprintf("
=== TITANIC SURVIVAL ANALYSIS REPORT ===

Dataset Overview:
- Total passengers analyzed: %d
- Number of survivors: %d
- Overall survival rate: %.1f%%

Key Findings:
1. Gender Impact: Women had %.1f%% survival rate vs %.1f%% for men
2. Class Impact: First class %.1f%%, Second class %.1f%%, Third class %.1f%%
3. Age Impact: Average age of survivors was %.1f vs %.1f for non-survivors

Statistical Model:
- Logistic regression accuracy: %.3f
- Most significant predictors: Gender, Passenger Class, Age
- Model identifies key survival factors with high statistical significance

Recommendations for Historical Understanding:
- Social norms ('women and children first') strongly influenced survival
- Economic status (class/fare) provided access to better safety resources
- Age was a factor, with children prioritized for rescue

Files Generated:
- Cleaned dataset: data/titanic_clean.csv
- Summary statistics: data/summary_statistics.csv
- Statistical model: data/logistic_regression_model.rds
- Visualizations: plots/ directory
- Interactive tables and plots available in analysis session
",
nrow(titanic_clean),
sum(titanic_clean$Survived == "Yes"),
mean(titanic_clean$Survived == "Yes") * 100,
mean(titanic_clean$Survived[titanic_clean$Sex == "female"] == "Yes") * 100,
mean(titanic_clean$Survived[titanic_clean$Sex == "male"] == "Yes") * 100,
mean(titanic_clean$Survived[titanic_clean$Pclass == "First"] == "Yes") * 100,
mean(titanic_clean$Survived[titanic_clean$Pclass == "Second"] == "Yes") * 100,
mean(titanic_clean$Survived[titanic_clean$Pclass == "Third"] == "Yes") * 100,
mean(titanic_clean$Age[titanic_clean$Survived == "Yes"], na.rm = TRUE),
mean(titanic_clean$Age[titanic_clean$Survived == "No"], na.rm = TRUE),
accuracy)

cat(final_report)

# Save report to file
writeLines(final_report, "reports/titanic_analysis_final_report.txt")
```

## Best Practices Demonstrated

This R workflow demonstrates several best practices:

1. **Tidyverse Ecosystem**: Using dplyr, ggplot2, and tidyr for consistent syntax
2. **Reproducible Analysis**: Clear code structure and documentation
3. **Statistical Rigor**: Appropriate tests and model validation
4. **Professional Visualization**: ggplot2 with consistent theming
5. **Interactive Elements**: plotly integration for exploration
6. **Report Generation**: Quarto for reproducible reporting
7. **Data Export**: Saving results in multiple formats

## What's Next?

To extend this R project, you could:

- Add machine learning models (Random Forest, SVM)
- Perform time series analysis (if temporal data available)
- Create a Shiny web application
- Add advanced statistical tests
- Implement cross-validation

## Summary

You have completed a comprehensive R data science workflow in Positron:

✅ Set up a professional R project structure
✅ Used tidyverse for data manipulation and cleaning
✅ Performed comprehensive exploratory data analysis
✅ Created publication-quality visualizations with ggplot2
✅ Conducted statistical hypothesis testing
✅ Built and evaluated a logistic regression model
✅ Generated interactive plots and tables
✅ Created reproducible reports with Quarto
✅ Saved and exported all results professionally

You now have experience with end-to-end R data science workflows in Positron!
